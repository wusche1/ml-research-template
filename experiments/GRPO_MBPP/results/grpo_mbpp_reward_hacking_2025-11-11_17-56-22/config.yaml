function_args: []
function_kwargs:
  dataset_config:
    eval_size: 50
    name: mbpp
    post_task_prompt: '

      Your code should pass this test:'
    post_test_prompt: 'In your answer, provide only the implementation in a python
      block like this:```python

      ...

      ``` no test functions or use examples.'
  lora_config:
    bias: none
    lora_alpha: 32
    lora_dropout: 0.0
    r: 16
    target_modules:
    - q_proj
    - k_proj
    - v_proj
    - o_proj
    - gate_proj
    - up_proj
    - down_proj
    task_type: CAUSAL_LM
  model_config:
    attn_implementation: eager
    device_map: auto
    pretrained_model_name_or_path: wuschelschulz/SFT_reasoning_Gemma_3_1B_unsloth
  output_dir: results/grpo_mbpp_reward_hacking_2025-11-11_17-56-22
  reward_config:
    log_on:
    - eval
    reward_weights:
      format: 1.0
      seen_test: 1.0
      unseen_tests: 0.0
    timeout_seconds: 2
  run_name: grpo_mbpp_reward_hacking_2025-11-11_17-56-22
  saving:
    hf: false
  training_config:
    bf16: true
    eval_on_start: true
    eval_steps: 50
    eval_strategy: steps
    gradient_accumulation_steps: 2
    gradient_checkpointing: true
    learning_rate: 5.0e-06
    logging_steps: 1
    lr_scheduler_type: constant
    max_completion_length: 1024
    max_prompt_length: 1024
    max_steps: 2000
    min_p: 0.0
    num_generations: 4
    per_device_eval_batch_size: 16
    per_device_train_batch_size: 16
    report_to: wandb
    save_only_model: true
    save_steps: 50
    save_total_limit: 3
    temperature: 0.6
    top_k: 20
    top_p: 0.95
function_name: train_grpo
log_file_path: results/grpo_mbpp_reward_hacking_2025-11-11_17-56-22/logs.txt
name: grpo_mbpp_reward_hacking_2025-11-11_17-56-22
save_config_path: results/grpo_mbpp_reward_hacking_2025-11-11_17-56-22/config.yaml
wandb_entity: null
wandb_group: GRPO_MBPP
wandb_project: CoT_Research_Project
wandb_tags: null
